#!/bin/bash

# performance_test_auto.sh
# Board Service ìë™ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì •ë¨)

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

# Configuration
BASE_URL="http://localhost:8000"
USER_SERVICE_URL="http://localhost:8080"

# Test user credentials
TEST_EMAIL="perftest@example.com"
TEST_PASSWORD="password123"
TEST_NAME="Performance Test User"

#ì„±ëŠ¥í…ŒìŠ¤íŠ¸ - ì•„ë˜ ê²½ìš°ì— ë”°ë¼ ìˆ˜ì •
# 1. í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ ì„±ëŠ¥ í™•ì¸
#TEST_REQUESTS=20, CONCURRENT_USERS=3

# 2. ì¤‘ê°„ ë¶€í•˜ë¡œ ì•ˆì •ì„± í™•ì¸
#TEST_REQUESTS=100, CONCURRENT_USERS=10

# 3. ë†’ì€ ë¶€í•˜ì—ì„œ í•œê³„ì  ì°¾ê¸°
#TEST_REQUESTS=300, CONCURRENT_USERS=30

# 4. Redis ìºì‹œ íš¨ê³¼ í™•ì¸
#TEST_REQUESTS=1000, CONCURRENT_USERS=1  # ë‹¨ì¼ ì‚¬ìš©ì, ë§ì€ ìš”ì²­

# Performance test settings
WARMUP_REQUESTS=5
TEST_REQUESTS=500
CONCURRENT_USERS=20

# Global variables
TOKEN=""
PROJECT_ID=""
WORKSPACE_ID=""

echo -e "${BLUE}============================================${NC}"
echo -e "${BLUE} Board Service ìë™ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸${NC}"
echo -e "${BLUE}============================================${NC}"

# Function to print step
print_step() {
    echo -e "\n${YELLOW}ğŸ“‹ $1${NC}"
}

# Function to print success
print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

# Function to print error
print_error() {
    echo -e "${RED}âŒ $1${NC}"
    exit 1
}

# Function to make API call
api_call() {
    local method=$1
    local url=$2
    local data=$3
    local headers=$4

    if [ -n "$data" ]; then
        if [ -n "$headers" ]; then
            curl -s -X $method "$url" -H "Content-Type: application/json" -H "$headers" -d "$data"
        else
            curl -s -X $method "$url" -H "Content-Type: application/json" -d "$data"
        fi
    else
        if [ -n "$headers" ]; then
            curl -s -X $method "$url" -H "$headers"
        else
            curl -s -X $method "$url"
        fi
    fi
}

# Setup: Create test environment
setup_test_environment() {
    print_step "ğŸ”§ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì¤‘..."

    # Health check (ìˆ˜ì •ë¨)
    response=$(api_call "GET" "$BASE_URL/health")
    if ! echo "$response" | grep -q '"status":"healthy"'; then
        print_error "Health check failed: $response"
    fi

    # Register/Login user (ìˆ˜ì •ë¨)
    register_data="{\"email\":\"$TEST_EMAIL\",\"password\":\"$TEST_PASSWORD\",\"name\":\"$TEST_NAME\"}"
    api_call "POST" "$USER_SERVICE_URL/api/auth/signup" "$register_data" > /dev/null 2>&1 || true

    login_data="{\"email\":\"$TEST_EMAIL\",\"password\":\"$TEST_PASSWORD\"}"
    login_response=$(api_call "POST" "$USER_SERVICE_URL/api/auth/login" "$login_data")

    if echo "$login_response" | grep -q "accessToken"; then
        TOKEN=$(echo "$login_response" | grep -o '"accessToken":"[^"]*"' | cut -d'"' -f4)
        print_success "ë¡œê·¸ì¸ ì„±ê³µ"
    else
        print_error "ë¡œê·¸ì¸ ì‹¤íŒ¨: $login_response"
    fi

    # Create workspace (ìˆ˜ì •ë¨)
    workspace_data="{\"name\":\"Performance Test Workspace\",\"description\":\"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©\"}"
    workspace_response=$(api_call "POST" "$BASE_URL/api/workspaces" "$workspace_data" "Authorization: Bearer $TOKEN")

    if echo "$workspace_response" | grep -q '"data"'; then
        WORKSPACE_ID=$(echo "$workspace_response" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)
        print_success "Workspace ìƒì„± ì™„ë£Œ"
    else
        print_error "Workspace ìƒì„± ì‹¤íŒ¨: $workspace_response"
    fi

    # Create project with kanbans (ìˆ˜ì •ë¨)
    project_data="{\"workspaceId\":\"$WORKSPACE_ID\",\"name\":\"Performance Test Project\",\"description\":\"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©\"}"
    project_response=$(api_call "POST" "$BASE_URL/api/projects" "$project_data" "Authorization: Bearer $TOKEN")

    if echo "$project_response" | grep -q '"data"'; then
        PROJECT_ID=$(echo "$project_response" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)
        print_success "Project ìƒì„± ì™„ë£Œ"
    else
        print_error "Project ìƒì„± ì‹¤íŒ¨: $project_response"
    fi

    # Create some test kanbans (ìˆ˜ì •ë¨)
    stages_response=$(api_call "GET" "$BASE_URL/api/custom-fields/projects/$PROJECT_ID/stages" "" "Authorization: Bearer $TOKEN")
    STAGE_ID=$(echo "$stages_response" | grep -o '"id":"[^"]*"' | sed -n '2p' | cut -d'"' -f4)

    roles_response=$(api_call "GET" "$BASE_URL/api/custom-fields/projects/$PROJECT_ID/roles" "" "Authorization: Bearer $TOKEN")
    ROLE_ID=$(echo "$roles_response" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)

    importance_response=$(api_call "GET" "$BASE_URL/api/custom-fields/projects/$PROJECT_ID/importance" "" "Authorization: Bearer $TOKEN")
    IMPORTANCE_ID=$(echo "$importance_response" | grep -o '"id":"[^"]*"' | sed -n '2p' | cut -d'"' -f4)

    # Create multiple kanbans for realistic test
    for i in {1..10}; do
        kanban_data="{\"projectId\":\"$PROJECT_ID\",\"title\":\"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¹¸ë°˜ $i\",\"roleIds\":[\"$ROLE_ID\"],\"stageId\":\"$STAGE_ID\",\"importanceId\":\"$IMPORTANCE_ID\"}"
        api_call "POST" "$BASE_URL/api/kanbans" "$kanban_data" "Authorization: Bearer $TOKEN" > /dev/null
    done

    print_success "í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ (ì¹¸ë°˜ 10ê°œ)"
}

# Performance test function
run_performance_test() {
    local test_name=$1
    local url=$2
    local method=${3:-GET}
    local data=${4:-""}

    print_step "ğŸš€ $test_name ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"

    # Warmup
    echo -e "${CYAN}ì›Œë°ì—… ì¤‘... ($WARMUP_REQUESTS ìš”ì²­)${NC}"
    for i in $(seq 1 $WARMUP_REQUESTS); do
        if [ -n "$data" ]; then
            curl -s -X $method "$url" -H "Content-Type: application/json" -H "Authorization: Bearer $TOKEN" -d "$data" > /dev/null
        else
            curl -s -H "Authorization: Bearer $TOKEN" "$url" > /dev/null
        fi
    done

    # Actual test
    echo -e "${CYAN}ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘... ($TEST_REQUESTS ìš”ì²­)${NC}"

    total_time=0
    min_time=999999
    max_time=0
    failed_requests=0

    # Results array
    declare -a response_times

    for i in $(seq 1 $TEST_REQUESTS); do
        start_time=$(date +%s%N)

        if [ -n "$data" ]; then
            response=$(curl -s -w "%{http_code}" -X $method "$url" -H "Content-Type: application/json" -H "Authorization: Bearer $TOKEN" -d "$data")
        else
            response=$(curl -s -w "%{http_code}" -H "Authorization: Bearer $TOKEN" "$url")
        fi

        end_time=$(date +%s%N)
        duration=$(((end_time - start_time) / 1000000))  # Convert to milliseconds

        # Check if request was successful
        http_code="${response: -3}"
        if [[ "$http_code" =~ ^2[0-9][0-9]$ ]]; then
            response_times[$i]=$duration
            total_time=$((total_time + duration))

            if [ $duration -lt $min_time ]; then
                min_time=$duration
            fi

            if [ $duration -gt $max_time ]; then
                max_time=$duration
            fi

            echo -ne "\rRequest $i/$TEST_REQUESTS: ${duration}ms (HTTP $http_code)"
        else
            failed_requests=$((failed_requests + 1))
            echo -ne "\rRequest $i/$TEST_REQUESTS: FAILED (HTTP $http_code)"
        fi
    done

    echo # New line

    # Calculate statistics
    successful_requests=$((TEST_REQUESTS - failed_requests))
    if [ $successful_requests -gt 0 ]; then
        avg_time=$((total_time / successful_requests))

        # Calculate percentiles (simple approach)
        sorted_times=($(printf '%s\n' "${response_times[@]}" | sort -n))
        p50_index=$(((successful_requests * 50) / 100))
        p95_index=$(((successful_requests * 95) / 100))
        p99_index=$(((successful_requests * 99) / 100))

        p50=${sorted_times[$p50_index]:-0}
        p95=${sorted_times[$p95_index]:-0}
        p99=${sorted_times[$p99_index]:-0}

        # Calculate throughput
        throughput=$(echo "scale=2; $successful_requests / ($total_time / 1000)" | bc -l 2>/dev/null || echo "N/A")

        # Print results
        echo -e "\n${GREEN}ğŸ“Š $test_name ì„±ëŠ¥ ê²°ê³¼:${NC}"
        echo -e "   ì„±ê³µí•œ ìš”ì²­: $successful_requests/$TEST_REQUESTS"
        echo -e "   ì‹¤íŒ¨í•œ ìš”ì²­: $failed_requests"
        echo -e "   í‰ê·  ì‘ë‹µì‹œê°„: ${avg_time}ms"
        echo -e "   ìµœì†Œ ì‘ë‹µì‹œê°„: ${min_time}ms"
        echo -e "   ìµœëŒ€ ì‘ë‹µì‹œê°„: ${max_time}ms"
        echo -e "   50th percentile: ${p50}ms"
        echo -e "   95th percentile: ${p95}ms"
        echo -e "   99th percentile: ${p99}ms"
        if [ "$throughput" != "N/A" ]; then
            echo -e "   ì²˜ë¦¬ëŸ‰: ${throughput} req/sec"
        fi

        # Performance evaluation
        if [ $avg_time -lt 100 ]; then
            echo -e "   ${GREEN}âœ… ì„±ëŠ¥ í‰ê°€: ìš°ìˆ˜${NC}"
        elif [ $avg_time -lt 500 ]; then
            echo -e "   ${YELLOW}âš ï¸  ì„±ëŠ¥ í‰ê°€: ë³´í†µ${NC}"
        else
            echo -e "   ${RED}âŒ ì„±ëŠ¥ í‰ê°€: ê°œì„  í•„ìš”${NC}"
        fi
    else
        echo -e "${RED}âŒ ëª¨ë“  ìš”ì²­ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.${NC}"
    fi
}

# Concurrent test function
run_concurrent_test() {
    local test_name=$1
    local url=$2

    print_step "ğŸ”„ $test_name ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ($CONCURRENT_USERSëª… ë™ì‹œ ì‚¬ìš©ì)"

    # Create background processes
    pids=()

    start_time=$(date +%s)

    for user in $(seq 1 $CONCURRENT_USERS); do
        {
            for req in $(seq 1 $((TEST_REQUESTS / CONCURRENT_USERS))); do
                curl -s -H "Authorization: Bearer $TOKEN" "$url" > /dev/null
            done
        } &
        pids+=($!)
    done

    # Wait for all background processes
    for pid in "${pids[@]}"; do
        wait $pid
    done

    end_time=$(date +%s)
    total_duration=$((end_time - start_time))

    echo -e "${GREEN}ğŸ“Š ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼:${NC}"
    echo -e "   ë™ì‹œ ì‚¬ìš©ì: $CONCURRENT_USERSëª…"
    echo -e "   ì´ ìš”ì²­: $TEST_REQUESTSê°œ"
    echo -e "   ì´ ì†Œìš”ì‹œê°„: ${total_duration}ì´ˆ"
    echo -e "   í‰ê·  ì²˜ë¦¬ëŸ‰: $(echo "scale=2; $TEST_REQUESTS / $total_duration" | bc -l) req/sec"
}

# Cleanup function
cleanup() {
    print_step "ğŸ§¹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì¤‘..."

    if [ -n "$WORKSPACE_ID" ] && [ -n "$TOKEN" ]; then
        api_call "DELETE" "$BASE_URL/api/workspaces/$WORKSPACE_ID" "" "Authorization: Bearer $TOKEN" > /dev/null 2>&1 || true
        print_success "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ"
    fi
}

# Main execution
main() {
    # Setup
    setup_test_environment

    echo -e "\n${BLUE}============================================${NC}"
    echo -e "${BLUE} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘${NC}"
    echo -e "${BLUE}============================================${NC}"

    # Test different endpoints
    run_performance_test "Stage-based Board View" "$BASE_URL/api/projects/$PROJECT_ID/orders/stage-board"

    run_performance_test "Role-based Board View" "$BASE_URL/api/projects/$PROJECT_ID/orders/role-board"

    run_performance_test "Project ìƒì„¸ ì¡°íšŒ" "$BASE_URL/api/projects/$PROJECT_ID"

    run_performance_test "ì¹¸ë°˜ ëª©ë¡ ì¡°íšŒ" "$BASE_URL/api/kanbans?projectId=$PROJECT_ID"

    run_performance_test "ì»¤ìŠ¤í…€ í•„ë“œ ì¡°íšŒ" "$BASE_URL/api/custom-fields/projects/$PROJECT_ID/stages"

    # Concurrent tests
    run_concurrent_test "Stage Board ë™ì‹œ ì ‘ê·¼" "$BASE_URL/api/projects/$PROJECT_ID/orders/stage-board"

    # Summary
    echo -e "\n${BLUE}============================================${NC}"
    echo -e "${BLUE} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ${NC}"
    echo -e "${BLUE}============================================${NC}"
    print_success "ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"

    # Cleanup
    cleanup
}

# Trap to ensure cleanup on exit
trap cleanup EXIT

# Run main function
main
